"""
üß† GESTURE INTEGRATOR - Coordina detectores e interpretadores NYX
===============================================================
Conecta todos los detectores con sus interpretadores y el pipeline principal.
Maneja sincronizaci√≥n, priorizaci√≥n, fusi√≥n de gestos y mapeo a acciones.
"""

import time
import threading
import queue
from typing import Dict, List, Optional, Any, Tuple
import logging
from enum import Enum
import json
import numpy as np
from collections import deque

logger = logging.getLogger(__name__)


class GesturePriority(Enum):
    """Prioridades de gestos para resoluci√≥n de conflictos."""
    HIGH = 3      # Gestos cr√≠ticos (emergencia, activaci√≥n)
    MEDIUM = 2    # Gestos de control principal
    LOW = 1       # Gestos de navegaci√≥n/ajuste
    BACKGROUND = 0 # Gestos de contexto


class GestureType(Enum):
    """Tipos de gestos reconocidos."""
    HAND = "hand"
    ARM = "arm"
    POSE = "pose"
    VOICE = "voice"
    COMBINED = "combined"


class GestureIntegrator:
    """
    Integra todos los detectores e interpretadores del sistema NYX.
    Versi√≥n completa y robusta combinando ambas implementaciones.
    """
    
    def __init__(self, config: Dict):
        """
        Inicializa el integrador de gestos.
        
        Args:
            config: Configuraci√≥n del sistema
        """
        self.config = config
        
        # Componentes registrados
        self.detectors = {}      # Dict[str, detector]: {'arm': ArmDetector, 'hand': HandDetector}
        self.interpreters = {}   # Dict[str, interpreter]: {'arm': ArmInterpreter, 'hand': GestureInterpreter}
        
        # Referencias a otros componentes
        self.pipeline = None          # Referencia a GesturePipeline
        self.profile_runtime = None   # Referencia a ProfileRuntime
        self.action_executor = None   # Referencia a ActionExecutor (opcional)
        
        # Colas para comunicaci√≥n
        self.detection_queue = queue.Queue(maxsize=100)    # Detecciones crudas
        self.interpretation_queue = queue.Queue(maxsize=50) # Gestos interpretados
        self.action_queue = queue.Queue(maxsize=20)        # Acciones listas para ejecutar
        
        # Hilos de procesamiento
        self.integration_thread = None
        self.processing_thread = None
        self.action_thread = None
        self.running = False
        
        # Estado del sistema
        self.active_detectors = set()    # Detectores activos
        self.active_interpreters = set() # Interpretadores activos
        self.current_profile = None      # Perfil actual
        self.gesture_mappings = {}       # Mapeos cargados
        
        # Historial para estabilizaci√≥n y depuraci√≥n
        self.gesture_history = []
        self.detection_history = []
        self.action_history = []
        self.max_history = 100
        
        # Configuraci√≥n
        self.enable_arm_detection = config.get('arm_detection', {}).get('enabled', False)
        self.enable_hand_detection = config.get('hand_detection', {}).get('enabled', True)
        self.gesture_timeout = 0.5       # Timeout para gestos (segundos)
        self.conflict_resolution_enabled = True
        self.min_gesture_confidence = config.get('general', {}).get('min_gesture_confidence', 0.6)
        
        # Bloqueos para acceso seguro a recursos compartidos
        self.lock = threading.RLock()
        self.stats_lock = threading.Lock()
        
        # Estad√≠sticas
        self.stats = {
            'total_detections': 0,
            'total_interpretations': 0,
            'total_actions_queued': 0,
            'total_actions_executed': 0,
            'gestures_per_second': 0,
            'avg_processing_time': 0.0,
            'detector_stats': {},
            'interpreter_stats': {},
            'errors': 0,
            'queue_overflows': 0
        }
        
        # Para c√°lculo de FPS y m√©tricas
        self.frame_times = deque(maxlen=30)
        self.processing_times = deque(maxlen=30)
        self.start_time = time.time()
        
        # Nuevas estructuras para funcionalidades faltantes
        self._initialize_missing_components()
        
        # --- Voice Activation State ---
        self.fist_start_time = None
        self.is_voice_active = False
        self.fist_hold_threshold = 1.5  # seconds (Faster activation)
        self.gesture_loss_time = None   # Grace period timer
        
        logger.info("‚úÖ GestureIntegrator inicializado (versi√≥n completa)")
    
    def set_pipeline(self, pipeline):
        """Asocia el pipeline al integrador."""
        self.pipeline = pipeline


    def _initialize_missing_components(self):
        """Inicializa componentes faltantes identificados en el an√°lisis."""
        # Buffer para gestos combinados (mano + brazo)
        self.combined_gesture_buffer = []
        self.max_combined_buffer = 5
        
        # Timeouts para diferentes tipos de gestos
        self.gesture_timeouts = {
            'hand': 0.3,
            'arm': 0.5,
            'pose': 0.8,
            'voice': 1.0,
            'combined': 0.4
        }
        
        # Configuraci√≥n de fusi√≥n de gestos
        self.fusion_config = {
            'enable_hand_arm_fusion': True,
            'enable_multi_hand_fusion': True,
            'fusion_window_ms': 300,
            'min_fusion_confidence': 0.4
        }
        
        # Contexto de gestos recientes
        self.recent_gestures_context = {
            'last_hand_gesture': None,
            'last_arm_gesture': None,
            'last_voice_command': None,
            'continuous_gestures': {},
            'sequence_buffer': []
        }
        
        # Estado de gestos continuos (como swipe, zoom, etc.)
        self.continuous_gesture_states = {}
        
        # Temporizadores
        self.last_frame_time = 0
        self.last_gesture_emission = 0
        
        # Configuraci√≥n de debounce
        self.debounce_config = {
            'same_gesture_ms': 300,
            'different_gesture_ms': 150,
            'enable_debounce': True
        }
    
    # ========== M√âTODOS FALTANTES IDENTIFICADOS ==========
    
    def _fuse_gestures(self, gestures: List[Dict]) -> List[Dict]:
        """
        Fusiona m√∫ltiples gestos detectados simult√°neamente.
        
        Args:
            gestures: Lista de gestos a fusionar
            
        Returns:
            Lista de gestos fusionados
        """
        if not self.fusion_config['enable_hand_arm_fusion'] or len(gestures) < 2:
            return gestures
        
        fused_gestures = []
        processed_indices = set()
        
        current_time = time.time()
        
        # Buscar combinaciones mano-brazo
        for i, gesture1 in enumerate(gestures):
            if i in processed_indices:
                continue
                
            for j, gesture2 in enumerate(gestures[i+1:], start=i+1):
                if j in processed_indices:
                    continue
                
                # Verificar si son de tipos compatibles para fusi√≥n
                if self._are_gestures_fusible(gesture1, gesture2):
                    fused = self._create_fused_gesture(gesture1, gesture2)
                    if fused:
                        fused_gestures.append(fused)
                        processed_indices.add(i)
                        processed_indices.add(j)
                        break
        
        # Agregar gestos no fusionados
        for i, gesture in enumerate(gestures):
            if i not in processed_indices:
                fused_gestures.append(gesture)
        
        return fused_gestures
    
    def _are_gestures_fusible(self, gesture1: Dict, gesture2: Dict) -> bool:
        """Determina si dos gestos pueden fusionarse."""
        type1 = gesture1.get('type', '')
        type2 = gesture2.get('type', '')
        
        # Combinaciones v√°lidas para fusi√≥n
        fusible_pairs = [
            ('hand', 'arm'),  # Mano + brazo
            ('left_hand', 'right_hand'),  # Dos manos
            ('hand', 'pose'),  # Mano + postura
        ]
        
        pair = (type1, type2)
        reverse_pair = (type2, type1)
        
        # Verificar si es una combinaci√≥n fusible
        if pair in fusible_pairs or reverse_pair in fusible_pairs:
            # Verificar temporalidad (deben ser casi simult√°neos)
            time_diff = abs(gesture1.get('timestamp', 0) - gesture2.get('timestamp', 0))
            return time_diff < (self.fusion_config['fusion_window_ms'] / 1000.0)
        
        return False
    
    def _create_fused_gesture(self, gesture1: Dict, gesture2: Dict) -> Optional[Dict]:
        """Crea un gesto fusionado a partir de dos gestos."""
        try:
            # Determinar tipos
            types = [gesture1.get('type', ''), gesture2.get('type', '')]
            
            # Crear gesto fusionado
            fused_gesture = {
                'type': 'combined',
                'timestamp': max(gesture1.get('timestamp', 0), gesture2.get('timestamp', 0)),
                'confidence': (gesture1.get('confidence', 0) + gesture2.get('confidence', 0)) / 2,
                'sources': [gesture1.get('type'), gesture2.get('type')],
                'original_gestures': [gesture1, gesture2],
                'detectors': [gesture1.get('detector', ''), gesture2.get('detector', '')]
            }
            
            # Combinar informaci√≥n espec√≠fica seg√∫n tipos
            if 'hand' in types and 'arm' in types:
                # Fusi√≥n mano-brazo
                hand_gesture = gesture1 if 'hand' in gesture1.get('type', '') else gesture2
                arm_gesture = gesture1 if 'arm' in gesture1.get('type', '') else gesture2
                
                fused_gesture.update({
                    'gesture': f"{hand_gesture.get('gesture', '')}_{arm_gesture.get('gesture', '')}",
                    'hand_data': hand_gesture,
                    'arm_data': arm_gesture,
                    'description': f"{hand_gesture.get('description', '')} con {arm_gesture.get('description', '')}"
                })
            
            elif 'left_hand' in types and 'right_hand' in types:
                # Fusi√≥n de dos manos
                fused_gesture.update({
                    'gesture': 'two_hand_' + gesture1.get('gesture', ''),
                    'left_hand': gesture1 if 'left' in gesture1.get('type', '') else gesture2,
                    'right_hand': gesture2 if 'right' in gesture2.get('type', '') else gesture1,
                    'description': f"Dos manos: {gesture1.get('description', '')}"
                })
            
            # Aplicar mapeo de perfil al gesto fusionado
            self._apply_profile_mapping(fused_gesture)
            
            return fused_gesture
            
        except Exception as e:
            logger.error(f"‚ùå Error creando gesto fusionado: {e}")
            return None
    
    def _update_continuous_gesture(self, gesture: Dict):
        """Actualiza el estado de un gesto continuo."""
        gesture_name = gesture.get('gesture', '')
        
        # Gestos que pueden ser continuos (swipe, zoom, rotate, etc.)
        continuous_gestures = ['swipe', 'pan', 'zoom', 'rotate', 'drag', 'scroll']
        
        is_continuous = any(cont_gesture in gesture_name for cont_gesture in continuous_gestures)
        
        if is_continuous:
            gesture_id = f"{gesture_name}_{gesture.get('type', '')}"
            
            if gesture_id not in self.continuous_gesture_states:
                # Iniciar nuevo gesto continuo
                self.continuous_gesture_states[gesture_id] = {
                    'start_time': time.time(),
                    'last_update': time.time(),
                    'gesture_data': gesture,
                    'update_count': 1
                }
            else:
                # Actualizar gesto continuo existente
                state = self.continuous_gesture_states[gesture_id]
                state['last_update'] = time.time()
                state['update_count'] += 1
                
                # Agregar datos acumulativos
                if 'delta_x' in gesture:
                    state.setdefault('total_delta_x', 0)
                    state['total_delta_x'] += gesture.get('delta_x', 0)
                
                if 'delta_y' in gesture:
                    state.setdefault('total_delta_y', 0)
                    state['total_delta_y'] += gesture.get('delta_y', 0)
                
                # Actualizar el gesto con informaci√≥n acumulada
                gesture['continuous'] = True
                gesture['continuous_duration'] = time.time() - state['start_time']
                gesture['continuous_updates'] = state['update_count']
                
                if 'total_delta_x' in state:
                    gesture['total_delta_x'] = state['total_delta_x']
                
                if 'total_delta_y' in state:
                    gesture['total_delta_y'] = state['total_delta_y']
    
    def process_gesture(self, gesture_data: Dict) -> Optional[Dict]:
        """
        Procesa un gesto individual (m√©todo para integraci√≥n con Pipeline).
        
        Args:
            gesture_data: Datos del gesto detectado
            
        Returns:
            Acci√≥n a ejecutar o None
        """
        try:
            gesture_type = gesture_data.get('type', 'hand')
            
            # 1. Interpretar (si hay int√©rprete)
            interpreted = gesture_data
            if gesture_type in self.interpreters:
                interpreter = self.interpreters[gesture_type]
                if hasattr(interpreter, 'process_gesture'):
                    result = interpreter.process_gesture(gesture_data)
                    if result:
                        interpreted = result
            
            # 2. Mapear a acci√≥n
            if self.profile_runtime:
                # Buscar mapeo en perfil
                gesture_name = interpreted.get('gesture')
                action = self.profile_runtime.get_gesture_action(
                    gesture_name=gesture_name, 
                    source=gesture_type,
                    hand_type=gesture_data.get('hand', 'right')
                )
                
                if action:
                    # Mezclar datos del gesto interpretado con la acci√≥n
                    # Importante: Mantener datos como 'cursor'
                    full_action = action.copy()
                    full_action.update({
                        'gesture_data': interpreted, # Aqu√≠ va el cursor
                        'timestamp': time.time()
                    })
                    return full_action
                    return full_action
            
            # 3. Logic for Push-to-Talk (Pu√±o para Hablar)
            if gesture_type == 'hand' or gesture_type == 'arm':
                 gesture_name = interpreted.get('gesture')
                 
                 # Check for 'peace' (Victory) gesture for voice activation
                 if 'peace' in gesture_name.lower() or 'victory' in gesture_name.lower():
                     # Gesto presente: Limpiar buffer de p√©rdida
                     self.gesture_loss_time = None
                     
                     if self.fist_start_time is None:
                         # Start counting
                         self.fist_start_time = time.time()
                         logger.info("‚úåÔ∏è Victory detectado: Iniciando cuenta (3s)...")
                     else:
                         # Check duration
                         duration = time.time() - self.fist_start_time
                         if duration >= self.fist_hold_threshold and not self.is_voice_active:
                             logger.info("üéôÔ∏è ‚úÖ Voz Activada - ¬°Habla ahora!")
                             self._activate_voice_mode()
                 else:
                     # Gesto NO presente (o es otro)
                     should_reset = True
                     
                     # Si estamos contando, usar grace period
                     if self.fist_start_time is not None:
                         if self.gesture_loss_time is None:
                             self.gesture_loss_time = time.time()
                             should_reset = False
                             logger.debug("‚ö†Ô∏è Victory pattern lost, buffering...")
                         elif (time.time() - self.gesture_loss_time) < 0.5:
                             # Dentro del grace period, mantener estado
                             should_reset = False
                     
                     if should_reset:
                         # Reset if gesture is lost > grace period
                         self.gesture_loss_time = None
                         
                         if self.fist_start_time is not None:
                             self.fist_start_time = None
                             logger.info("‚úã Gesto liberado/perdido")
                         
                         # If voice was active, deactivate it immediately upon release
                         if self.is_voice_active:
                             logger.info("üéôÔ∏è Voz Desactivada")
                             self._deactivate_voice_mode()
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå Error en process_gesture integrador: {e}")
            return None

    def _cleanup_continuous_gestures(self):
        """Limpia gestos continuos que han expirado."""
        current_time = time.time()
        expired_gestures = []
        
        for gesture_id, state in self.continuous_gesture_states.items():
            # Si no ha sido actualizado en m√°s de 1 segundo, limpiar
            if current_time - state['last_update'] > 1.0:
                expired_gestures.append(gesture_id)
        
        for gesture_id in expired_gestures:
            del self.continuous_gesture_states[gesture_id]
    
    def _apply_debounce(self, gesture: Dict) -> bool:
        """Aplica debounce para evitar gestos duplicados demasiado r√°pido."""
        if not self.debounce_config['enable_debounce']:
            return True
        
        gesture_name = gesture.get('gesture', '')
        gesture_type = gesture.get('type', '')
        current_time = time.time()
        
        # Buscar gestos recientes del mismo tipo
        recent_same_gesture = None
        for g in reversed(self.gesture_history[-10:]):
            if g.get('gesture') == gesture_name and g.get('type') == gesture_type:
                recent_same_gesture = g
                break
        
        if recent_same_gesture:
            time_diff = current_time - recent_same_gesture.get('timestamp', 0)
            
            # Si es el mismo gesto muy reciente, aplicar debounce
            if time_diff < (self.debounce_config['same_gesture_ms'] / 1000.0):
                logger.debug(f"‚è±Ô∏è  Gestos duplicados muy r√°pido, ignorando: {gesture_name}")
                return False
        
        return True
    
    def _handle_gesture_sequence(self, gesture: Dict):
        """Maneja secuencias de gestos (como doble tap, combinaciones)."""
        current_time = time.time()
        gesture_name = gesture.get('gesture', '')
        
        # Agregar a buffer de secuencia
        self.recent_gestures_context['sequence_buffer'].append({
            'gesture': gesture_name,
            'timestamp': current_time,
            'type': gesture.get('type', ''),
            'data': gesture
        })
        
        # Mantener solo √∫ltimos 5 gestos en el buffer
        if len(self.recent_gestures_context['sequence_buffer']) > 5:
            self.recent_gestures_context['sequence_buffer'].pop(0)
        
        # Buscar patrones de secuencia
        sequence_patterns = self._detect_sequence_patterns()
        
        # Si se detecta un patr√≥n, crear gesto combinado
        for pattern in sequence_patterns:
            combined_gesture = self._create_sequence_gesture(pattern)
            if combined_gesture:
                # Aplicar mapeo de perfil
                self._apply_profile_mapping(combined_gesture)
                
                # Encolar para procesamiento
                try:
                    self.interpretation_queue.put(combined_gesture, timeout=0.01)
                    logger.debug(f"üîÑ Secuencia detectada: {pattern['name']}")
                except queue.Full:
                    pass
    
    def _detect_sequence_patterns(self) -> List[Dict]:
        """Detecta patrones en la secuencia de gestos recientes."""
        patterns = []
        buffer = self.recent_gestures_context['sequence_buffer']
        
        if len(buffer) < 2:
            return patterns
        
        # Patr√≥n: doble tap
        if len(buffer) >= 2:
            last_two = buffer[-2:]
            if (last_two[0]['gesture'] == last_two[1]['gesture'] and 
                'tap' in last_two[0]['gesture'].lower() and
                last_two[1]['timestamp'] - last_two[0]['timestamp'] < 0.5):
                
                patterns.append({
                    'name': f"double_{last_two[0]['gesture']}",
                    'gestures': last_two,
                    'type': 'sequence'
                })
        
        # Patr√≥n: gesto + gesto (combinaci√≥n)
        if len(buffer) >= 2:
            gesture_combo = f"{buffer[-2]['gesture']}_{buffer[-1]['gesture']}"
            patterns.append({
                'name': gesture_combo,
                'gestures': buffer[-2:],
                'type': 'combination'
            })
        
        return patterns
    
    def _create_sequence_gesture(self, pattern: Dict) -> Optional[Dict]:
        """Crea un gesto a partir de un patr√≥n de secuencia."""
        try:
            sequence_gesture = {
                'type': 'sequence',
                'gesture': pattern['name'],
                'timestamp': time.time(),
                'confidence': 0.8,  # Alta confianza para secuencias
                'sequence_data': pattern,
                'description': f"Secuencia: {pattern['name'].replace('_', ' ‚Üí ')}"
            }
            
            return sequence_gesture
            
        except Exception as e:
            logger.error(f"‚ùå Error creando gesto de secuencia: {e}")
            return None
    
    def _prioritize_gestures(self, gestures: List[Dict]) -> List[Dict]:
        """Prioriza gestos seg√∫n su importancia y contexto."""
        if not gestures:
            return []
        
        # Asignar prioridades
        prioritized = []
        for gesture in gestures:
            priority = self._calculate_gesture_priority(gesture)
            gesture['priority'] = priority
            prioritized.append(gesture)
        
        # Ordenar por prioridad (mayor primero)
        prioritized.sort(key=lambda x: x.get('priority', 0), reverse=True)
        
        return prioritized
    
    def _calculate_gesture_priority(self, gesture: Dict) -> int:
        """Calcula la prioridad de un gesto."""
        base_priority = 0
        
        # Prioridad por tipo
        type_priority = {
            'voice': GesturePriority.HIGH.value,
            'combined': GesturePriority.HIGH.value,
            'emergency': GesturePriority.HIGH.value,
            'arm': GesturePriority.MEDIUM.value,
            'hand': GesturePriority.MEDIUM.value,
            'pose': GesturePriority.LOW.value,
            'sequence': GesturePriority.MEDIUM.value
        }
        
        gesture_type = gesture.get('type', '')
        base_priority = type_priority.get(gesture_type, GesturePriority.LOW.value)
        
        # Aumentar prioridad por confianza
        confidence = gesture.get('confidence', 0)
        if confidence > 0.8:
            base_priority += 1
        
        # Aumentar prioridad si es gesto cr√≠tico
        critical_gestures = ['emergency_stop', 'help', 'pause', 'activate']
        if any(crit_gesture in gesture.get('gesture', '').lower() 
               for crit_gesture in critical_gestures):
            base_priority += 2
        
        # Reducir prioridad si es gesto continuo repetido
        if gesture.get('continuous', False):
            base_priority -= 1
        
        return max(1, min(base_priority, 5))  # Limitar entre 1 y 5
    
    def _route_to_interpreters(self, grouped_detections: Dict[str, List]):
        """Env√≠a detecciones a los interpretadores correspondientes."""
        for detection_type, detections in grouped_detections.items():
            if not detections:
                continue
            
            interpreter_name = detection_type
            if interpreter_name not in self.interpreters:
                continue
            
            interpreter = self.interpreters[interpreter_name]
            
            try:
                # Interpretar detecciones
                interpreted_gestures = interpreter.interpret(detections)
                
                if interpreted_gestures:
                    # Aplicar fusi√≥n si hay m√∫ltiples gestos
                    if len(interpreted_gestures) > 1 and self.fusion_config['enable_multi_hand_fusion']:
                        interpreted_gestures = self._fuse_gestures(interpreted_gestures)
                    
                    # Aplicar debounce
                    interpreted_gestures = [g for g in interpreted_gestures 
                                           if self._apply_debounce(g)]
                    
                    # Actualizar gestos continuos
                    for gesture in interpreted_gestures:
                        self._update_continuous_gesture(gesture)
                        self._handle_gesture_sequence(gesture)
                    
                    # Priorizar gestos
                    interpreted_gestures = self._prioritize_gestures(interpreted_gestures)
                    
                    # Agregar contexto adicional
                    for gesture in interpreted_gestures:
                        gesture['source'] = interpreter_name
                        gesture['detection_count'] = len(detections)
                        gesture['timestamp'] = time.time()
                        
                        # Aplicar mapeo de perfil si est√° disponible
                        self._apply_profile_mapping(gesture)
                    
                    # Encolar gestos interpretados
                    for gesture in interpreted_gestures:
                        try:
                            self.interpretation_queue.put(gesture, timeout=0.01)
                            with self.stats_lock:
                                self.stats['total_interpretations'] += 1
                        except queue.Full:
                            logger.warning(f"‚ö†Ô∏è Cola de interpretaciones llena, descartando gesto")
                            
            except Exception as e:
                logger.error(f"‚ùå Error en int√©rprete {interpreter_name}: {e}")
                with self.stats_lock:
                    self.stats['errors'] += 1
        
        # Limpiar gestos continuos expirados
        self._cleanup_continuous_gestures()
    
    def _validate_gesture(self, gesture: Dict) -> bool:
        """Valida un gesto interpretado."""
        # Validaciones b√°sicas
        required_fields = ['gesture', 'type', 'confidence', 'timestamp']
        if not all(field in gesture for field in required_fields):
            return False
        
        # Validar confianza m√≠nima
        if gesture.get('confidence', 0) < self.min_gesture_confidence:
            return False
        
        # Validar timestamp (no demasiado viejo)
        max_age = 2.0  # 2 segundos m√°ximo
        if time.time() - gesture.get('timestamp', 0) > max_age:
            return False
        
        # Validar que no sea gesto duplicado muy r√°pido
        if not self._apply_debounce(gesture):
            return False
        
        return True
    
    # ========== NUEVOS M√âTODOS P√öBLICOS PARA INTEGRACI√ìN ==========
    
    def enable_fusion(self, enable: bool = True):
        """Habilita o deshabilita la fusi√≥n de gestos."""
        self.fusion_config['enable_hand_arm_fusion'] = enable
        self.fusion_config['enable_multi_hand_fusion'] = enable
        logger.info(f"üîÑ Fusi√≥n de gestos {'habilitada' if enable else 'deshabilitada'}")
    
    def set_fusion_window(self, window_ms: int):
        """Establece la ventana temporal para fusi√≥n de gestos."""
        self.fusion_config['fusion_window_ms'] = max(100, min(window_ms, 1000))
        logger.info(f"üîÑ Ventana de fusi√≥n establecida: {self.fusion_config['fusion_window_ms']}ms")
    
    def enable_debounce(self, enable: bool = True):
        """Habilita o deshabilita el debounce de gestos."""
        self.debounce_config['enable_debounce'] = enable
        logger.info(f"üîÑ Debounce {'habilitado' if enable else 'deshabilitado'}")
    
    def get_continuous_gestures(self) -> Dict[str, Any]:
        """Obtiene el estado actual de gestos continuos."""
        with self.lock:
            return self.continuous_gesture_states.copy()
    
    def get_gesture_sequence(self) -> List[Dict]:
        """Obtiene la secuencia reciente de gestos."""
        with self.lock:
            return self.recent_gestures_context['sequence_buffer'].copy()
    
    def clear_gesture_sequence(self):
        """Limpia el buffer de secuencia de gestos."""
        with self.lock:
            self.recent_gestures_context['sequence_buffer'].clear()
            logger.info("üßπ Secuencia de gestos limpiada")
    
    def process_combined_gesture(self, gesture_data: Dict):
        """Procesa un gesto combinado manualmente."""
        try:
            # Validar gesto combinado
            if 'combined' not in gesture_data.get('type', ''):
                gesture_data['type'] = 'combined'
            
            # Asegurar campos requeridos
            if 'timestamp' not in gesture_data:
                gesture_data['timestamp'] = time.time()
            
            if 'confidence' not in gesture_data:
                gesture_data['confidence'] = 0.7
            
            # Aplicar mapeo de perfil
            self._apply_profile_mapping(gesture_data)
            
            # Encolar para procesamiento
            self.interpretation_queue.put(gesture_data, timeout=0.01)
            logger.debug(f"üîÑ Gesto combinado procesado: {gesture_data.get('gesture', '')}")
            
        except Exception as e:
            logger.error(f"‚ùå Error procesando gesto combinado: {e}")
    
    # ========== M√âTODOS DE PROCESAMIENTO MEJORADOS ==========
    
    def _processing_loop(self):
        """Bucle de procesamiento mejorado con nuevas funcionalidades."""
        logger.debug("üîÑ Iniciando bucle de procesamiento mejorado")
        
        while self.running:
            try:
                # Obtener gesto interpretado
                gesture = self.interpretation_queue.get(timeout=0.1)
                self.interpretation_queue.task_done()
                
                # Validar gesto
                if not self._validate_gesture(gesture):
                    continue
                
                # Resolver conflictos con gestos previos
                if self.conflict_resolution_enabled:
                    if not self._resolve_conflicts(gesture):
                        continue
                
                # Agregar al historial
                self._add_to_gesture_history(gesture)
                
                # Actualizar contexto de gestos recientes
                self._update_recent_gesture_context(gesture)
                
                # Si tiene acci√≥n mapeada, enviar a cola de acciones
                if gesture.get('mapped', False):
                    action_data = self._create_action_data(gesture)
                    
                    try:
                        self.action_queue.put(action_data, timeout=0.01)
                        with self.stats_lock:
                            self.stats['total_actions_queued'] += 1
                    except queue.Full:
                        logger.warning(f"‚ö†Ô∏è Cola de acciones llena, descartando acci√≥n")
                
                # Notificar al pipeline si est√° disponible
                if self.pipeline and hasattr(self.pipeline, 'handle_interpreted_gesture'):
                    try:
                        self.pipeline.handle_interpreted_gesture(gesture)
                    except Exception as e:
                        logger.debug(f"‚ö†Ô∏è Pipeline no pudo manejar gesto: {e}")
                
                # Emitir se√±al de gesto detectado (para UI)
                self._emit_gesture_signal(gesture)
                
            except queue.Empty:
                continue
            except Exception as e:
                logger.error(f"‚ùå Error en bucle de procesamiento: {e}")
                with self.stats_lock:
                    self.stats['errors'] += 1
    
    def _update_recent_gesture_context(self, gesture: Dict):
        """Actualiza el contexto de gestos recientes."""
        gesture_type = gesture.get('type', '')
        
        if gesture_type == 'hand':
            self.recent_gestures_context['last_hand_gesture'] = gesture
        elif gesture_type == 'arm':
            self.recent_gestures_context['last_arm_gesture'] = gesture
        elif gesture_type == 'voice':
            self.recent_gestures_context['last_voice_command'] = gesture
        
        # Limitar tama√±o del contexto
        for key in ['last_hand_gesture', 'last_arm_gesture', 'last_voice_command']:
            context_item = self.recent_gestures_context.get(key)
            if context_item and time.time() - context_item.get('timestamp', 0) > 10.0:
                self.recent_gestures_context[key] = None
    
    def _resolve_conflicts(self, new_gesture: Dict) -> bool:
        """Resuelve conflictos entre gestos nuevos y previos mejorado."""
        if not self.gesture_history:
            return True
        
        # Obtener gestos recientes (√∫ltimo segundo)
        recent_gestures = [
            g for g in self.gesture_history[-10:]
            if time.time() - g.get('timestamp', 0) < 1.0
        ]
        
        if not recent_gestures:
            return True
        
        # Reglas de resoluci√≥n de conflictos mejoradas
        new_gesture_name = new_gesture.get('gesture')
        new_gesture_type = new_gesture.get('type')
        new_priority = new_gesture.get('priority', 0)
        
        for recent_gesture in recent_gestures:
            recent_name = recent_gesture.get('gesture')
            recent_type = recent_gesture.get('type')
            recent_priority = recent_gesture.get('priority', 0)
            
            # Mismo gesto muy r√°pido = posible duplicado
            if (new_gesture_name == recent_name and 
                new_gesture_type == recent_type):
                time_diff = new_gesture['timestamp'] - recent_gesture['timestamp']
                if time_diff < 0.2:  # Menos de 200ms = duplicado seguro
                    logger.debug(f"‚ö†Ô∏è Gesto duplicado filtrado: {new_gesture_name}")
                    return False
            
            # Conflictos de prioridad
            if new_priority < recent_priority:
                # Gestos de menor prioridad ignorados si hay uno de mayor prioridad reciente
                time_diff = new_gesture['timestamp'] - recent_gesture['timestamp']
                if time_diff < 0.5:  # Medio segundo
                    logger.debug(f"‚ö†Ô∏è Gesto de baja prioridad ignorado: {new_gesture_name}")
                    return False
            
            # Conflictos mano/brazo con contexto
            if (new_gesture_type == 'hand' and recent_type == 'arm' or
                new_gesture_type == 'arm' and recent_type == 'hand'):
                
                # Si hay gesto continuo activo, priorizarlo
                if recent_gesture.get('continuous', False):
                    logger.debug(f"‚ö†Ô∏è Gesto de {new_gesture_type} ignorado por gesto continuo de {recent_type}")
                    return False
        
        return True
    
    def _create_action_data(self, gesture: Dict) -> Dict:
        """Crea datos de acci√≥n a partir de un gesto mejorado."""
        action_data = {
            'type': 'gesture',
            'gesture': gesture['gesture'],
            'action': gesture.get('action'),
            'command': gesture.get('command'),
            'confidence': gesture.get('confidence', 0.5),
            'timestamp': time.time(),
            'source': gesture.get('source', 'unknown'),
            'gesture_type': gesture.get('type', 'unknown'),
            'priority': gesture.get('priority', 1),
            'gesture_data': gesture
        }
        
        # Agregar informaci√≥n adicional para gestos continuos
        if gesture.get('continuous', False):
            action_data['continuous'] = True
            action_data['continuous_duration'] = gesture.get('continuous_duration', 0)
            action_data['continuous_updates'] = gesture.get('continuous_updates', 1)
            
            if 'total_delta_x' in gesture:
                action_data['total_delta_x'] = gesture['total_delta_x']
            
            if 'total_delta_y' in gesture:
                action_data['total_delta_y'] = gesture['total_delta_y']
        
        # Agregar informaci√≥n de secuencia si existe
        if 'sequence_data' in gesture:
            action_data['sequence'] = True
            action_data['sequence_name'] = gesture.get('gesture', '')
        
        return action_data
    
    # ========== M√âTODO PARA COMANDOS DE VOZ MEJORADO ==========
    
    def process_voice_command(self, voice_data: Dict):
        """
        Procesa un comando de voz directamente.
        
        Args:
            voice_data: Datos del comando de voz
        """
        if not self.running or 'voice' not in self.interpreters:
            return
        
        try:
            # Agregar metadatos
            voice_data['detector'] = 'voice'
            voice_data['timestamp'] = time.time()
            voice_data.setdefault('confidence', 0.9)
            
            # Enviar directamente al VoiceInterpreter
            interpreter = self.interpreters['voice']
            interpreted_action = interpreter.interpret([voice_data])
            
            if interpreted_action and isinstance(interpreted_action, list):
                for action in interpreted_action:
                    action['source'] = 'voice'
                    action['detection_count'] = 1
                    
                    # Aplicar mapeo de perfil
                    if self.profile_runtime:
                        self._apply_profile_mapping(action)
                    
                    # Priorizar gestos de voz (alta prioridad)
                    action['priority'] = GesturePriority.HIGH.value
                    
                    # Encolar para procesamiento
                    try:
                        self.interpretation_queue.put(action, timeout=0.01)
                        logger.debug(f"üé§ Comando de voz procesado: {voice_data.get('text', '')}")
                    except queue.Full:
                        logger.warning("‚ö†Ô∏è Cola de interpretaciones llena, descartando comando de voz")
                        
        except Exception as e:
            logger.error(f"‚ùå Error procesando comando de voz: {e}")
    
    # ========== REGISTRO DE COMPONENTES MEJORADO ==========
    
    def register_detector(self, name: str, detector: Any):
        """
        Registra un detector en el integrador.
        
        Args:
            name: Nombre del detector ('hand', 'arm', 'pose', 'voice')
            detector: Instancia del detector
        """
        with self.lock:
            self.detectors[name] = detector
            self.active_detectors.add(name)
            
            # Inicializar estad√≠sticas del detector
            self.stats['detector_stats'][name] = {
                'calls': 0,
                'successes': 0,
                'errors': 0,
                'last_call': 0,
                'avg_processing_time': 0
            }
            
            logger.info(f"‚úÖ Detector '{name}' registrado con estad√≠sticas")
    
    def register_interpreter(self, name: str, interpreter: Any):
        """
        Registra un int√©rprete en el integrador.
        
        Args:
            name: Nombre del int√©rprete ('hand', 'arm', 'voice')
            interpreter: Instancia del int√©rprete
        """
        with self.lock:
            self.interpreters[name] = interpreter
            self.active_interpreters.add(name)
            
            # Inicializar estad√≠sticas del int√©rprete
            self.stats['interpreter_stats'][name] = {
                'calls': 0,
                'gestures_interpreted': 0,
                'errors': 0,
                'last_call': 0,
                'avg_processing_time': 0
            }
            
            logger.info(f"‚úÖ Int√©rprete '{name}' registrado con estad√≠sticas")
    
    def start(self):
        """Inicia el integrador de gestos."""
        if self.running:
            return
            
        self.running = True
        
        # Iniciar hilos
        self.processing_thread = threading.Thread(
            target=self._processing_loop,
            daemon=True,
            name="NYX-Integrator-Processing"
        )
        self.processing_thread.start()
        
        logger.info("‚ñ∂Ô∏è GestureIntegrator iniciado")

    def stop(self):
        """Detiene el integrador de gestos."""
        self.running = False
        if self.processing_thread and self.processing_thread.is_alive():
            self.processing_thread.join(timeout=1.0)
        logger.info("‚èπÔ∏è GestureIntegrator detenido")

    def set_profile_runtime(self, profile_runtime):
        """Configura el perfil activo."""
        self.profile_runtime = profile_runtime
        if profile_runtime:
            self.current_profile = profile_runtime.name
            logger.info(f"üîÑ Perfil '{self.current_profile}' cargado en Integrador")

    def load_profile(self, profile_data: Dict):
        """Carga un perfil desde sus datos."""
        try:
            from core.profile_runtime import ProfileRuntime
            self.profile_runtime = ProfileRuntime(profile_data)
            self.current_profile = profile_data.get('name', 'unknown')
            logger.info(f"‚úÖ Perfil '{self.current_profile}' cargado en Integrador")
        except Exception as e:
            logger.error(f"‚ùå Error cargando perfil en Integrador: {e}")

    def _apply_profile_mapping(self, gesture: Dict):
        """Busca mapeo en perfil y marca el gesto como mapeado."""
        if not self.profile_runtime:
            return
            
        gesture_name = gesture.get('gesture')
        source = gesture.get('source', 'hand')
        hand_type = gesture.get('hand', 'right')
        
        action = self.profile_runtime.get_gesture_action(
            gesture_name=gesture_name, 
            source=source,
            hand_type=hand_type
        )
        
        if action:
            gesture['mapped'] = True
            gesture['action'] = action.get('action')
            gesture['command'] = action.get('command')
            # Para visualizaci√≥n en UI
            gesture['action_name'] = f"{action.get('action')}:{action.get('command')}"
        else:
            gesture['mapped'] = False

    def _emit_gesture_signal(self, gesture: Dict):
        """Emite se√±al de gesto detectado para la UI."""
        if self.pipeline and hasattr(self.pipeline, 'gesture_detected'):
            # El pipeline de NYX usa esta se√±al para actualizar la UI
            self.pipeline.gesture_detected.emit(gesture)

    def get_actions(self) -> List[Dict]:
        """Obtiene y limpia la cola de acciones (para integraci√≥n pulsada)."""
        actions = []
        try:
            while not self.action_queue.empty():
                actions.append(self.action_queue.get_nowait())
                self.action_queue.task_done()
        except queue.Empty:
            pass
        return actions

    def add_detection(self, source_type: str, detections: List[Dict]):
        """Agrega detecciones crudas a la cola de procesamiento."""
        if not self.running:
            return
            
        grouped = {source_type: detections}
        # Podr√≠amos usar la cola detection_queue, pero para NYX es m√°s r√°pido procesar directo
        self._route_to_interpreters(grouped)


# ========== CLASES AUXILIARES PARA INTEGRACI√ìN ==========

class GestureBuffer:
    """Buffer para almacenar y procesar gestos temporalmente."""
    
    def __init__(self, max_size: int = 10, max_age: float = 2.0):
        self.max_size = max_size
        self.max_age = max_age
        self.buffer = deque(maxlen=max_size)
    
    def add(self, gesture: Dict):
        """Agrega un gesto al buffer."""
        self.buffer.append({
            'gesture': gesture,
            'timestamp': time.time()
        })
    
    def get_recent(self, min_confidence: float = 0.0) -> List[Dict]:
        """Obtiene gestos recientes que cumplan con la confianza m√≠nima."""
        current_time = time.time()
        recent = []
        
        for item in reversed(self.buffer):
            if current_time - item['timestamp'] > self.max_age:
                break
            
            if item['gesture'].get('confidence', 0) >= min_confidence:
                recent.append(item['gesture'])
        
        return recent
    
    def clear(self):
        """Limpia el buffer."""
        self.buffer.clear()


class GestureSequenceDetector:
    """Detector de secuencias de gestos."""
    
    def __init__(self):
        self.sequences = {
            'double_tap': {'pattern': ['tap', 'tap'], 'max_interval': 0.5},
            'swipe_tap': {'pattern': ['swipe', 'tap'], 'max_interval': 1.0},
            'zoom_in_out': {'pattern': ['pinch_in', 'pinch_out'], 'max_interval': 1.5}
        }
    
    def detect(self, gesture_history: List[Dict]) -> List[Dict]:
        """Detecta secuencias en el historial de gestos."""
        detected_sequences = []
        
        for seq_name, seq_config in self.sequences.items():
            pattern = seq_config['pattern']
            max_interval = seq_config['max_interval']
            
            if len(gesture_history) >= len(pattern):
                # Buscar el patr√≥n en el historial reciente
                recent_gestures = gesture_history[-len(pattern):]
                gesture_names = [g.get('gesture', '') for g in recent_gestures]
                
                # Verificar si coincide el patr√≥n
                if all(g in p for g, p in zip(gesture_names, pattern)):
                    # Verificar intervalos temporales
                    timestamps = [g.get('timestamp', 0) for g in recent_gestures]
                    intervals = [timestamps[i+1] - timestamps[i] 
                               for i in range(len(timestamps)-1)]
                    
                    if all(interval <= max_interval for interval in intervals):
                        detected_sequences.append({
                            'name': seq_name,
                            'gestures': recent_gestures,
                            'confidence': min(g.get('confidence', 0.5) 
                                            for g in recent_gestures)
                        })
        
        return detected_sequences



    def _activate_voice_mode(self):
        """Activates the voice recognition mode (Push-to-Talk)."""
        logger.info("üéôÔ∏è Fist held for 3s -> ACTIVATING MICROPHONE")
        self.is_voice_active = True
        
        # Notify Pipeline to Start Listening strictly
        if self.pipeline and hasattr(self.pipeline, 'start_voice_listening'):
            self.pipeline.start_voice_listening()
            
        # Emit signal or visual feedback via action queue
        feedback_action = {
            'type': 'system',
            'action': 'feedback',
            'command': 'show_notification',
            'title': 'Micr√≥fono Activado',
            'message': 'Escuchando...',
            'duration': 2000,
            'icon': 'mic'
        }
        self.action_queue.put(feedback_action)

    def _deactivate_voice_mode(self):
        """Deactivates the voice recognition mode."""
        logger.info("üîá Fist released -> MUTING MICROPHONE")
        self.is_voice_active = False
        
        # Notify Pipeline to Stop Listening
        if self.pipeline and hasattr(self.pipeline, 'stop_voice_listening'):
            self.pipeline.stop_voice_listening()

        # Emit signal or visual feedback via action queue
        feedback_action = {
            'type': 'system',
            'action': 'feedback',
            'command': 'show_notification',
            'title': 'Micr√≥fono Desactivado',
            'message': 'Silenciado',
            'duration': 1000,
            'icon': 'mic_off'
        }
        self.action_queue.put(feedback_action)

logger.info("‚úÖ Todos los m√©todos faltantes han sido integrados en GestureIntegrator")